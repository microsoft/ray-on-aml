{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Testing for Interactive use case\r\n",
        "\r\n",
        "Before you run this example, please make sure you have all the right version of libraries in Compute Instance.\r\n",
        "\r\n",
        "And aslo note that after you finish running jobs in Ray Cluster, make sure you run __ray.shutdown()__ to stop your Compute Cluster. \r\n",
        "\r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make sure you have correct environment for Ray on AML\r\n",
        "\r\n",
        "To have the best experience Ray on Azure Machine Learning Services **Python 3.8.x** and **Ray 1.9.0** are recommened."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\r\n",
        "import ray\r\n",
        "\r\n",
        "if not (sys.version_info.major == 3 and sys.version_info.minor == 8):\r\n",
        "    print(\"Python 3.8 or higher is required.\")\r\n",
        "    print(\"Change kerner to azureml_py38\")\r\n",
        "    print(\"                 ^^^^^^^^^^^\")\r\n",
        "else:\r\n",
        "    print(f\"{sys.version_info.major}.{sys.version_info.minor} is detected.\")\r\n",
        "\r\n",
        "if not ray.__version__.startswith('1.9'):\r\n",
        "    print(\"User Ray is not 1.9\")\r\n",
        "    print(\"pip install ray==1.9.0\")\r\n",
        "    print(\"           ^^^^^^^^^^^\")\r\n",
        "else:\r\n",
        "    print(f\"{ray.__version__} is detected\")\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "3.8 is detected.\n1.9.0 is detected\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639462908020
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade ray-on-aml"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "from azureml.core import Workspace, Experiment, Environment, Datastore, Dataset, ScriptRunConfig\n",
        "from azureml.core.runconfig import PyTorchConfiguration\n",
        "# from azureml.widgets import RunDetails\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "from azureml.core.runconfig import PyTorchConfiguration\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "import platform\n",
        "import sys\n",
        "# sys.path.append(\"../\") # go to parent dir\n",
        "import importlib\n"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1639462947012
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#You can pre-provision \"worker-cpu-v3\" in the same vnet with your compute instance\n",
        "from ray_on_aml.core import Ray_On_AML\n",
        "ws = Workspace.from_config()\n",
        "# shin-dask-vnet/dask-public\n",
        "# net_rg = None, compute_cluster = 'cpu-cluster', vm_size='STANDARD_DS3_V2',vnet='rayvnet', subnet='default'\n",
        "\n",
        "ray_on_aml =Ray_On_AML(ws=ws, compute_cluster =\"worker-cpu-v3\", vnet_rg = 'shin-dask-rg', vnet='shin-dask-vnet', subnet='dask-public' )\n",
        "_, ray = ray_on_aml.getRay()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "rank returned is  None\nrank returned is  None\nazureml_py38\nFound existing cluster, use it.\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2021-12-14 06:22:37,400\tINFO services.py:1338 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n2021-12-14 06:22:54,856\tINFO worker.py:842 -- Connecting to existing Ray cluster at address: 10.1.0.5:6379\n2021-12-14 06:22:54,990\tWARNING worker.py:1219 -- The autoscaler failed with the following error:\nTerminated with signal 15\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 543, in <module>\n    monitor.run()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 439, in run\n    self._run()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 346, in _run\n    time.sleep(AUTOSCALER_UPDATE_INTERVAL_S)\n\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1639463119365
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ray.cluster_resources()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "{'node:10.1.0.11': 1.0,\n 'object_store_memory': 24777734552.0,\n 'memory': 56622848412.0,\n 'CPU': 24.0,\n 'node:10.1.0.9': 1.0,\n 'node:10.1.0.5': 1.0,\n 'node:10.1.0.7': 1.0,\n 'node:10.1.0.8': 1.0,\n 'node:10.1.0.4': 1.0}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1639463388122
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ray_on_aml.shutdown()\n",
        "ray.shutdown()"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1639463390695
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing with Dask on Ray"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# import ray\n",
        "# ray.init()\n",
        "from ray.util.dask import ray_dask_get\n",
        "import dask\n",
        "import dask.array as da\n",
        "import dask.dataframe as dd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "dask.config.set(scheduler=ray_dask_get)\n",
        "d_arr = da.from_array(np.random.randint(0, 1000, size=(256, 256)))\n",
        "\n",
        "# The Dask scheduler submits the underlying task graph to Ray.\n",
        "d_arr.mean().compute(scheduler=ray_dask_get)\n",
        "\n",
        "# Set the scheduler to ray_dask_get in your config so you don't have to\n",
        "# specify it on each compute call.\n",
        "\n",
        "df = dd.from_pandas(\n",
        "    pd.DataFrame(\n",
        "        np.random.randint(0, 10000, size=(1024, 2)), columns=[\"age\", \"grade\"]),\n",
        "    npartitions=2)\n",
        "df.groupby([\"age\"]).mean().compute()\n",
        "\n",
        "# ray.shutdown()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "       grade\nage         \n11    1604.0\n13    4258.5\n16    2995.0\n27    1715.0\n37    5443.0\n...      ...\n9901  7171.0\n9916   932.0\n9962  5476.0\n9986  2555.0\n9987  2220.0\n\n[981 rows x 1 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>grade</th>\n    </tr>\n    <tr>\n      <th>age</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>1604.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>4258.5</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2995.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>1715.0</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>5443.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9901</th>\n      <td>7171.0</td>\n    </tr>\n    <tr>\n      <th>9916</th>\n      <td>932.0</td>\n    </tr>\n    <tr>\n      <th>9962</th>\n      <td>5476.0</td>\n    </tr>\n    <tr>\n      <th>9986</th>\n      <td>2555.0</td>\n    </tr>\n    <tr>\n      <th>9987</th>\n      <td>2220.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>981 rows × 1 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1639428544183
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import dask.dataframe as dd\n",
        "\n",
        "# storage_options = {'account_name': 'azureopendatastorage'}\n",
        "# ddf = dd.read_parquet('az://nyctlc/green/puYear=2019/puMonth=*/*.parquet', storage_options=storage_options)\n",
        "# ddf.count().compute()\n",
        "#This still have error about parquet, need to fix, might be lib version conflict"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1639104458150
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dask\n",
        "\n",
        "# import ray\n",
        "from ray.util.dask import ray_dask_get\n",
        "import dask\n",
        "import dask.array as da\n",
        "import dask.dataframe as dd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import dask\n",
        "import dask.dataframe as dd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "from azureml.core import Workspace, Dataset, Model\n",
        "from adlfs import AzureBlobFileSystem\n",
        "\n",
        "abfs = AzureBlobFileSystem(account_name=\"azureopendatastorage\",  container_name=\"isdweatherdatacontainer\")\n",
        "\n",
        "data = ray.data.read_parquet(\"az://isdweatherdatacontainer/ISDWeather/year=2009\", filesystem=abfs)\n",
        "\n",
        "data.count()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Metadata Fetch Progress: 100%|██████████| 16/16 [00:08<00:00,  1.78it/s]\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "98904376"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1639428612158
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Ray Tune for distributed ML tunning"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "# import ray\n",
        "from ray import tune\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        # In this example, we don't change the model architecture\n",
        "        # due to simplicity.\n",
        "        self.conv1 = nn.Conv2d(1, 3, kernel_size=3)\n",
        "        self.fc = nn.Linear(192, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 3))\n",
        "        x = x.view(-1, 192)\n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "# Change these values if you want the training to run quicker or slower.\n",
        "EPOCH_SIZE = 512\n",
        "TEST_SIZE = 256\n",
        "\n",
        "def train(model, optimizer, train_loader):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # We set this just for the example to run quickly.\n",
        "        if batch_idx * len(data) > EPOCH_SIZE:\n",
        "            return\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "def test(model, data_loader):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(data_loader):\n",
        "            # We set this just for the example to run quickly.\n",
        "            if batch_idx * len(data) > TEST_SIZE:\n",
        "                break\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            outputs = model(data)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "    return correct / total\n",
        "def train_mnist(config):\n",
        "    # Data Setup\n",
        "    mnist_transforms = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize((0.1307, ), (0.3081, ))])\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        datasets.MNIST(\"~/data\", train=True, download=True, transform=mnist_transforms),\n",
        "        batch_size=64,\n",
        "        shuffle=True)\n",
        "    test_loader = DataLoader(\n",
        "        datasets.MNIST(\"~/data\", train=False, transform=mnist_transforms),\n",
        "        batch_size=64,\n",
        "        shuffle=True)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = ConvNet()\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = optim.SGD(\n",
        "        model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"])\n",
        "    for i in range(10):\n",
        "        train(model, optimizer, train_loader)\n",
        "        acc = test(model, test_loader)\n",
        "\n",
        "        # Send the current training result back to Tune\n",
        "        tune.report(mean_accuracy=acc)\n",
        "\n",
        "        if i % 5 == 0:\n",
        "            # This saves the model to the trial directory\n",
        "            torch.save(model.state_dict(), \"./model.pth\")\n",
        "search_space = {\n",
        "    \"lr\": tune.sample_from(lambda spec: 10**(-10 * np.random.rand())),\n",
        "    \"momentum\": tune.uniform(0.01, 0.09)\n",
        "}\n",
        "\n",
        "# Uncomment this to enable distributed execution\n",
        "# ray.shutdown()\n",
        "# ray.init(address=\"auto\",ignore_reinit_error=True)\n",
        "# ray.init(address =f'ray://{headnode_private_ip}:10001',allow_multiple=True,ignore_reinit_error=True )\n",
        "# Download the dataset first\n",
        "datasets.MNIST(\"~/data\", train=True, download=True)\n",
        "\n",
        "analysis = tune.run(train_mnist, config=search_space)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2021-12-14 00:43:56,877\tWARNING function_runner.py:561 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n2021-12-14 00:43:56,917\tINFO logger.py:605 -- pip install \"ray[tune]\" to see TensorBoard files.\n2021-12-14 00:43:56,918\tWARNING callback.py:114 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "== Status ==<br>Current time: 2021-12-14 00:43:57 (running for 00:00:00.12)<br>Memory usage on this node: 5.7/13.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/24 CPUs, 0/0 GPUs, 0.0/51.83 GiB heap, 0.0/22.62 GiB objects<br>Result logdir: /home/azureuser/ray_results/train_mnist_2021-12-14_00-43-56<br>Number of trials: 1/1 (1 PENDING)<br><table>\n<thead>\n<tr><th>Trial name             </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  momentum</th></tr>\n</thead>\n<tbody>\n<tr><td>train_mnist_eb850_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.000300904</td><td style=\"text-align: right;\"> 0.0760256</td></tr>\n</tbody>\n</table><br><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2021-12-14 00:43:57,371\tERROR trial_runner.py:958 -- Trial train_mnist_eb850_00000: Error processing event.\nTraceback (most recent call last):\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 924, in _process_trial\n    results = self.trial_executor.fetch_result(trial)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 787, in fetch_result\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n    return func(*args, **kwargs)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/worker.py\", line 1715, in get\n    raise value\nray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::ImplicitFunc.__init__()\u001b[39m (pid=424, ip=10.1.0.13)\nRuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n\n\u001b[36mray::ImplicitFunc.__init__()\u001b[39m (pid=424, ip=10.1.0.13)\n  File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/ray/cloudpickle/cloudpickle.py\", line 679, in subimport\n    __import__(name)\n  File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/torchvision/__init__.py\", line 6, in <module>\n    from torchvision import models\n  File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/torchvision/models/__init__.py\", line 12, in <module>\n    from . import detection\n  File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/torchvision/models/detection/__init__.py\", line 1, in <module>\n    from .faster_rcnn import *\n  File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/torchvision/models/detection/faster_rcnn.py\", line 7, in <module>\n    from torchvision.ops import misc as misc_nn_ops\n  File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/torchvision/ops/__init__.py\", line 1, in <module>\n    from .boxes import nms, batched_nms, remove_small_boxes, clip_boxes_to_image, box_area, box_iou, generalized_box_iou\n  File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/torchvision/ops/boxes.py\", line 45, in <module>\n    @torch.jit._script_if_tracing\nAttributeError: module 'torch.jit' has no attribute '_script_if_tracing'\n\u001b[2m\u001b[36m(TemporaryActor pid=424, ip=10.1.0.13)\u001b[0m 2021-12-14 00:43:57,366\tERROR worker.py:431 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::ImplicitFunc.__init__()\u001b[39m (pid=424, ip=10.1.0.13)\n\u001b[2m\u001b[36m(TemporaryActor pid=424, ip=10.1.0.13)\u001b[0m RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n\u001b[2m\u001b[36m(TemporaryActor pid=424, ip=10.1.0.13)\u001b[0m \n\u001b[2m\u001b[36m(TemporaryActor pid=424, ip=10.1.0.13)\u001b[0m \u001b[36mray::ImplicitFunc.__init__()\u001b[39m (pid=424, ip=10.1.0.13)\n\u001b[2m\u001b[36m(TemporaryActor pid=424, ip=10.1.0.13)\u001b[0m   File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/ray/cloudpickle/cloudpickle.py\", line 679, in subimport\n\u001b[2m\u001b[36m(TemporaryActor pid=424, ip=10.1.0.13)\u001b[0m     __import__(name)\n\u001b[2m\u001b[36m(TemporaryActor pid=424, ip=10.1.0.13)\u001b[0m   File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/torchvision/__init__.py\", line 6, in <module>\n\u001b[2m\u001b[36m(TemporaryActor pid=424, ip=10.1.0.13)\u001b[0m     from torchvision import models\n\u001b[2m\u001b[36m(TemporaryActor pid=424, ip=10.1.0.13)\u001b[0m   File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/torchvision/models/__init__.py\", line 12, in <module>\n\u001b[2m\u001b[36m(TemporaryActor pid=424, ip=10.1.0.13)\u001b[0m     from . import detection\n\u001b[2m\u001b[36m(TemporaryActor pid=424, ip=10.1.0.13)\u001b[0m   File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/torchvision/models/detection/__init__.py\", line 1, in <module>\n\u001b[2m\u001b[36m(TemporaryActor pid=424, ip=10.1.0.13)\u001b[0m     from .faster_rcnn import *\n\u001b[2m\u001b[36m(TemporaryActor pid=424, ip=10.1.0.13)\u001b[0m   File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/torchvision/models/detection/faster_rcnn.py\", line 7, in <module>\n\u001b[2m\u001b[36m(TemporaryActor pid=424, ip=10.1.0.13)\u001b[0m     from torchvision.ops import misc as misc_nn_ops\n\u001b[2m\u001b[36m(TemporaryActor pid=424, ip=10.1.0.13)\u001b[0m   File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/torchvision/ops/__init__.py\", line 1, in <module>\n\u001b[2m\u001b[36m(TemporaryActor pid=424, ip=10.1.0.13)\u001b[0m     from .boxes import nms, batched_nms, remove_small_boxes, clip_boxes_to_image, box_area, box_iou, generalized_box_iou\n\u001b[2m\u001b[36m(TemporaryActor pid=424, ip=10.1.0.13)\u001b[0m   File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/torchvision/ops/boxes.py\", line 45, in <module>\n\u001b[2m\u001b[36m(TemporaryActor pid=424, ip=10.1.0.13)\u001b[0m     @torch.jit._script_if_tracing\n\u001b[2m\u001b[36m(TemporaryActor pid=424, ip=10.1.0.13)\u001b[0m AttributeError: module 'torch.jit' has no attribute '_script_if_tracing'\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Result for train_mnist_eb850_00000:\n  trial_id: eb850_00000\n  \n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "== Status ==<br>Current time: 2021-12-14 00:43:57 (running for 00:00:00.44)<br>Memory usage on this node: 5.7/13.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/24 CPUs, 0/0 GPUs, 0.0/51.83 GiB heap, 0.0/22.62 GiB objects<br>Result logdir: /home/azureuser/ray_results/train_mnist_2021-12-14_00-43-56<br>Number of trials: 1/1 (1 ERROR)<br><table>\n<thead>\n<tr><th>Trial name             </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  momentum</th></tr>\n</thead>\n<tbody>\n<tr><td>train_mnist_eb850_00000</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">0.000300904</td><td style=\"text-align: right;\"> 0.0760256</td></tr>\n</tbody>\n</table><br>Number of errored trials: 1<br><table>\n<thead>\n<tr><th>Trial name             </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                        </th></tr>\n</thead>\n<tbody>\n<tr><td>train_mnist_eb850_00000</td><td style=\"text-align: right;\">           1</td><td>/home/azureuser/ray_results/train_mnist_2021-12-14_00-43-56/train_mnist_eb850_00000_0_lr=0.0003009,momentum=0.076026_2021-12-14_00-43-57/error.txt</td></tr>\n</tbody>\n</table><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TuneError",
          "evalue": "('Trials did not complete', [train_mnist_eb850_00000])",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_13904/956064152.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"~/data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m \u001b[0manalysis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, queue_trials, loggers, _remote)\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [train_mnist_eb850_00000])"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1639106657384
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        " import sklearn.datasets\n",
        " import sklearn.metrics\n",
        " from sklearn.model_selection import train_test_split\n",
        " import xgboost as xgb\n",
        "\n",
        " from ray import tune\n",
        "\n",
        "\n",
        " def train_breast_cancer(config):\n",
        "     # Load dataset\n",
        "     data, labels = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
        "     # Split into train and test set\n",
        "     train_x, test_x, train_y, test_y = train_test_split(\n",
        "         data, labels, test_size=0.25)\n",
        "     # Build input matrices for XGBoost\n",
        "     train_set = xgb.DMatrix(train_x, label=train_y)\n",
        "     test_set = xgb.DMatrix(test_x, label=test_y)\n",
        "     # Train the classifier\n",
        "     results = {}\n",
        "     xgb.train(\n",
        "         config,\n",
        "         train_set,\n",
        "         evals=[(test_set, \"eval\")],\n",
        "         evals_result=results,\n",
        "         verbose_eval=False)\n",
        "     # Return prediction accuracy\n",
        "     accuracy = 1. - results[\"eval\"][\"error\"][-1]\n",
        "     tune.report(mean_accuracy=accuracy, done=True)\n",
        "\n",
        "\n",
        " config = {\n",
        "     \"objective\": \"binary:logistic\",\n",
        "     \"eval_metric\": [\"logloss\", \"error\"],\n",
        "     \"max_depth\": tune.randint(1, 9),\n",
        "     \"min_child_weight\": tune.choice([1, 2, 3]),\n",
        "     \"subsample\": tune.uniform(0.5, 1.0),\n",
        "     \"eta\": tune.loguniform(1e-4, 1e-1)\n",
        " }\n",
        " analysis = tune.run(\n",
        "     train_breast_cancer,\n",
        "     resources_per_trial={\"cpu\": 1},\n",
        "     config=config,\n",
        "     num_samples=10)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2021-12-14 00:44:11,009\tWARNING callback.py:114 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "== Status ==<br>Current time: 2021-12-14 00:44:12 (running for 00:00:01.00)<br>Memory usage on this node: 5.7/13.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/24 CPUs, 0/0 GPUs, 0.0/51.83 GiB heap, 0.0/22.62 GiB objects<br>Result logdir: /home/azureuser/ray_results/train_breast_cancer_2021-12-14_00-44-11<br>Number of trials: 10/10 (9 PENDING, 1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  min_child_weight</th><th style=\"text-align: right;\">  subsample</th></tr>\n</thead>\n<tbody>\n<tr><td>train_breast_cancer_f3ef5_00000</td><td>RUNNING </td><td>10.1.0.5:23891</td><td style=\"text-align: right;\">0.00186465 </td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.71512 </td></tr>\n<tr><td>train_breast_cancer_f3ef5_00001</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.00391335 </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.814205</td></tr>\n<tr><td>train_breast_cancer_f3ef5_00002</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.0537188  </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.829706</td></tr>\n<tr><td>train_breast_cancer_f3ef5_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.0570274  </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.818953</td></tr>\n<tr><td>train_breast_cancer_f3ef5_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.00288771 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.503914</td></tr>\n<tr><td>train_breast_cancer_f3ef5_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.000167493</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.757776</td></tr>\n<tr><td>train_breast_cancer_f3ef5_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.000111108</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.618197</td></tr>\n<tr><td>train_breast_cancer_f3ef5_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.000585458</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.750409</td></tr>\n<tr><td>train_breast_cancer_f3ef5_00008</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.000692446</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.810961</td></tr>\n<tr><td>train_breast_cancer_f3ef5_00009</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.0050665  </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.532366</td></tr>\n</tbody>\n</table><br><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Result for train_breast_cancer_f3ef5_00001:\n  date: 2021-12-14_00-44-12\n  done: true\n  experiment_id: 68117f4f09694788aad9e3e3ce611e91\n  hostname: fcddd95c17024a528498abb65fa46bc8000002\n  iterations_since_restore: 1\n  mean_accuracy: 0.895105\n  node_ip: 10.1.0.11\n  pid: 423\n  time_since_restore: 0.06230735778808594\n  time_this_iter_s: 0.06230735778808594\n  time_total_s: 0.06230735778808594\n  timestamp: 1639442652\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: f3ef5_00001\n  \nResult for train_breast_cancer_f3ef5_00000:\n  date: 2021-12-14_00-44-12\n  done: true\n  experiment_id: 279d327638884103abc5df2edab520a1\n  hostname: hyssh1\n  iterations_since_restore: 1\n  mean_accuracy: 0.93007\n  node_ip: 10.1.0.5\n  pid: 23891\n  time_since_restore: 0.4081110954284668\n  time_this_iter_s: 0.4081110954284668\n  time_total_s: 0.4081110954284668\n  timestamp: 1639442652\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: f3ef5_00000\n  \nResult for train_breast_cancer_f3ef5_00005:\n  date: 2021-12-14_00-44-12\n  done: true\n  experiment_id: c93b5602281b4a05a210a631e14786d4\n  hostname: fcddd95c17024a528498abb65fa46bc8000001\n  iterations_since_restore: 1\n  mean_accuracy: 0.916084\n  node_ip: 10.1.0.9\n  pid: 364\n  time_since_restore: 0.1194605827331543\n  time_this_iter_s: 0.1194605827331543\n  time_total_s: 0.1194605827331543\n  timestamp: 1639442652\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: f3ef5_00005\n  \nResult for train_breast_cancer_f3ef5_00003:\n  date: 2021-12-14_00-44-12\n  done: true\n  experiment_id: ed82e583bfc3448ab2236c89a0af7d95\n  hostname: fcddd95c17024a528498abb65fa46bc8000001\n  iterations_since_restore: 1\n  mean_accuracy: 0.951049\n  node_ip: 10.1.0.9\n  pid: 445\n  time_since_restore: 0.1364755630493164\n  time_this_iter_s: 0.1364755630493164\n  time_total_s: 0.1364755630493164\n  timestamp: 1639442652\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: f3ef5_00003\n  \nResult for train_breast_cancer_f3ef5_00004:\n  date: 2021-12-14_00-44-12\n  done: true\n  experiment_id: 4a8b1a342f4c4edc84b6183c05d8ac08\n  hostname: fcddd95c17024a528498abb65fa46bc8000003\n  iterations_since_restore: 1\n  mean_accuracy: 0.944056\n  node_ip: 10.1.0.12\n  pid: 340\n  time_since_restore: 0.13007092475891113\n  time_this_iter_s: 0.13007092475891113\n  time_total_s: 0.13007092475891113\n  timestamp: 1639442652\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: f3ef5_00004\n  \nResult for train_breast_cancer_f3ef5_00002:\n  date: 2021-12-14_00-44-12\n  done: true\n  experiment_id: ced4abbfc9514ab9a065d38cb29769fc\n  hostname: fcddd95c17024a528498abb65fa46bc8000006\n  iterations_since_restore: 1\n  mean_accuracy: 0.965035\n  node_ip: 10.1.0.15\n  pid: 342\n  time_since_restore: 0.1389150619506836\n  time_this_iter_s: 0.1389150619506836\n  time_total_s: 0.1389150619506836\n  timestamp: 1639442652\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: f3ef5_00002\n  \nResult for train_breast_cancer_f3ef5_00007:\n  date: 2021-12-14_00-44-12\n  done: true\n  experiment_id: ba0ce8fd314f40fcad44b62ad361e862\n  hostname: fcddd95c17024a528498abb65fa46bc8000004\n  iterations_since_restore: 1\n  mean_accuracy: 0.888112\n  node_ip: 10.1.0.13\n  pid: 344\n  time_since_restore: 0.12878918647766113\n  time_this_iter_s: 0.12878918647766113\n  time_total_s: 0.12878918647766113\n  timestamp: 1639442652\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: f3ef5_00007\n  \nResult for train_breast_cancer_f3ef5_00009:\n  date: 2021-12-14_00-44-12\n  done: true\n  experiment_id: 56543f4807f64a1180cd05b757d05579\n  hostname: fcddd95c17024a528498abb65fa46bc8000006\n  iterations_since_restore: 1\n  mean_accuracy: 0.93007\n  node_ip: 10.1.0.15\n  pid: 425\n  time_since_restore: 0.14608120918273926\n  time_this_iter_s: 0.14608120918273926\n  time_total_s: 0.14608120918273926\n  timestamp: 1639442652\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: f3ef5_00009\n  \nResult for train_breast_cancer_f3ef5_00008:\n  date: 2021-12-14_00-44-12\n  done: true\n  experiment_id: c07768e72bf94343b0f5841a62dfa54b\n  hostname: fcddd95c17024a528498abb65fa46bc8000003\n  iterations_since_restore: 1\n  mean_accuracy: 0.965035\n  node_ip: 10.1.0.12\n  pid: 422\n  time_since_restore: 0.14992022514343262\n  time_this_iter_s: 0.14992022514343262\n  time_total_s: 0.14992022514343262\n  timestamp: 1639442652\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: f3ef5_00008\n  \nResult for train_breast_cancer_f3ef5_00006:\n  date: 2021-12-14_00-44-12\n  done: true\n  experiment_id: e9a977f75627458eb8ae75dc31125257\n  hostname: fcddd95c17024a528498abb65fa46bc8000004\n  iterations_since_restore: 1\n  mean_accuracy: 0.937063\n  node_ip: 10.1.0.13\n  pid: 343\n  time_since_restore: 0.06719303131103516\n  time_this_iter_s: 0.06719303131103516\n  time_total_s: 0.06719303131103516\n  timestamp: 1639442652\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: f3ef5_00006\n  \n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "== Status ==<br>Current time: 2021-12-14 00:44:12 (running for 00:00:01.86)<br>Memory usage on this node: 5.5/13.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/24 CPUs, 0/0 GPUs, 0.0/51.83 GiB heap, 0.0/22.62 GiB objects<br>Result logdir: /home/azureuser/ray_results/train_breast_cancer_2021-12-14_00-44-11<br>Number of trials: 10/10 (10 TERMINATED)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  min_child_weight</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">     acc</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n</thead>\n<tbody>\n<tr><td>train_breast_cancer_f3ef5_00000</td><td>TERMINATED</td><td>10.1.0.5:23891</td><td style=\"text-align: right;\">0.00186465 </td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.71512 </td><td style=\"text-align: right;\">0.93007 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.408111 </td></tr>\n<tr><td>train_breast_cancer_f3ef5_00001</td><td>TERMINATED</td><td>10.1.0.11:423 </td><td style=\"text-align: right;\">0.00391335 </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.814205</td><td style=\"text-align: right;\">0.895105</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0623074</td></tr>\n<tr><td>train_breast_cancer_f3ef5_00002</td><td>TERMINATED</td><td>10.1.0.15:342 </td><td style=\"text-align: right;\">0.0537188  </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.829706</td><td style=\"text-align: right;\">0.965035</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.138915 </td></tr>\n<tr><td>train_breast_cancer_f3ef5_00003</td><td>TERMINATED</td><td>10.1.0.9:445  </td><td style=\"text-align: right;\">0.0570274  </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.818953</td><td style=\"text-align: right;\">0.951049</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.136476 </td></tr>\n<tr><td>train_breast_cancer_f3ef5_00004</td><td>TERMINATED</td><td>10.1.0.12:340 </td><td style=\"text-align: right;\">0.00288771 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.503914</td><td style=\"text-align: right;\">0.944056</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.130071 </td></tr>\n<tr><td>train_breast_cancer_f3ef5_00005</td><td>TERMINATED</td><td>10.1.0.9:364  </td><td style=\"text-align: right;\">0.000167493</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.757776</td><td style=\"text-align: right;\">0.916084</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.119461 </td></tr>\n<tr><td>train_breast_cancer_f3ef5_00006</td><td>TERMINATED</td><td>10.1.0.13:343 </td><td style=\"text-align: right;\">0.000111108</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.618197</td><td style=\"text-align: right;\">0.937063</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.067193 </td></tr>\n<tr><td>train_breast_cancer_f3ef5_00007</td><td>TERMINATED</td><td>10.1.0.13:344 </td><td style=\"text-align: right;\">0.000585458</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.750409</td><td style=\"text-align: right;\">0.888112</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.128789 </td></tr>\n<tr><td>train_breast_cancer_f3ef5_00008</td><td>TERMINATED</td><td>10.1.0.12:422 </td><td style=\"text-align: right;\">0.000692446</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.810961</td><td style=\"text-align: right;\">0.965035</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.14992  </td></tr>\n<tr><td>train_breast_cancer_f3ef5_00009</td><td>TERMINATED</td><td>10.1.0.15:425 </td><td style=\"text-align: right;\">0.0050665  </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.532366</td><td style=\"text-align: right;\">0.93007 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.146081 </td></tr>\n</tbody>\n</table><br><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2021-12-14 00:44:12,990\tINFO tune.py:626 -- Total run time: 1.99 seconds (1.84 seconds for the tuning loop).\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1639442652624
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Spark on Ray (#todo)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# import ray\n",
        "# import raydp\n",
        "# import os\n",
        "# ray.shutdown()\n",
        "# ray.init()\n",
        "# os.environ[\"PYSPARK_PYTHON\"]=\"/anaconda/envs/azureml_py38/bin/python3\"\n",
        "\n",
        "# # ray.init(address ='ray://10.0.0.11:6379')\n",
        "# spark = raydp.init_spark(\n",
        "#   app_name = \"example\",\n",
        "#   num_executors = 2,\n",
        "#   executor_cores = 1,\n",
        "#   executor_memory = \"1gb\"\n",
        "# )\n",
        "\n",
        "# # data =spark.read.format(\"csv\").option(\"header\", True).load(\"wasbs://ojsales-simulatedcontainer@azureopendatastorage.blob.core.windows.net/oj_sales_data/Store10*.csv\")\n",
        "\n",
        "\n",
        "# # # normal data processesing with Spark\n",
        "# # df = spark.createDataFrame([('look',), ('spark',), ('tutorial',), ('spark',), ('look', ), ('python', )], ['word'])\n",
        "# # df.show()\n",
        "# # word_count = df.groupBy('word').count()\n",
        "# # word_count.show()\n",
        "# import pandas as pd\n",
        "\n",
        "# from pyspark.sql.functions import col, pandas_udf\n",
        "# from pyspark.sql.types import LongType\n",
        "\n",
        "# # Declare the function and create the UDF\n",
        "# def multiply_func(a: pd.Series, b: pd.Series) -> pd.Series:\n",
        "#     return a * b\n",
        "\n",
        "# multiply = pandas_udf(multiply_func, returnType=LongType())\n",
        "\n",
        "# # The function for a pandas_udf should be able to execute with local Pandas data\n",
        "# x = pd.Series([1, 2, 3])\n",
        "# print(multiply_func(x, x))\n",
        "# # 0    1\n",
        "# # 1    4\n",
        "# # 2    9\n",
        "# # dtype: int64\n",
        "\n",
        "# # Create a Spark DataFrame, 'spark' is an existing SparkSession\n",
        "# df = spark.createDataFrame(pd.DataFrame(x, columns=[\"x\"]))\n",
        "\n",
        "# # Execute function as a Spark vectorized UDF\n",
        "# df.select(multiply(col(\"x\"), col(\"x\"))).show()\n",
        "# # +-------------------+\n",
        "# # |multiply_func(x, x)|\n",
        "# # +-------------------+\n",
        "# # |                  1|\n",
        "# # |                  4|\n",
        "# # |                  9|\n",
        "# # +-------------------+\n",
        "\n",
        "\n",
        "# # stop the spark cluster\n",
        "# raydp.stop_spark()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Ray on Job Cluster"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "\n",
        "# base_conda_dep =['adlfs>=2021.10.0','pytorch','matplotlib','torchvision','pip']\n",
        "# base_pip_dep = ['sklearn','xgboost','lightgbm','ray[default]==1.9.0', 'xgboost_ray', 'dask','pyarrow>=6.0.1', 'azureml-mlflow']\n",
        "compute_cluster = 'worker-cpu-v3'\n",
        "maxnode =5\n",
        "vm_size='STANDARD_DS3_V2'\n",
        "vnet='rayvnet'\n",
        "subnet='default'\n",
        "exp ='ray_on_aml_job'\n",
        "ws_detail = ws.get_details()\n",
        "ws_rg = ws_detail['id'].split(\"/\")[4]\n",
        "vnet_rg=None\n",
        "try:\n",
        "    ray_cluster = ComputeTarget(workspace=ws, name=compute_cluster)\n",
        "\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    if vnet_rg is None:\n",
        "        vnet_rg = ws_rg\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n",
        "                                                        min_nodes=0, max_nodes=maxnode,\n",
        "                                                        vnet_resourcegroup_name=vnet_rg,\n",
        "                                                        vnet_name=vnet,\n",
        "                                                        subnet_name=subnet)\n",
        "    ray_cluster = ComputeTarget.create(ws, compute_cluster, compute_config)\n",
        "\n",
        "    ray_cluster.wait_for_completion(show_output=True)\n",
        "\n",
        "\n",
        "# python_version = [\"python=\"+platform.python_version()]\n",
        "\n",
        "\n",
        "\n",
        "# conda_packages = python_version+base_conda_dep\n",
        "# pip_packages = base_pip_dep \n",
        "\n",
        "# conda_dep = CondaDependencies()\n",
        "\n",
        "# rayEnv = Environment(name=\"rayEnv\")\n",
        "rayEnv = Environment.get(ws, \"rayEnv\", version=18)\n",
        "# for conda_package in conda_packages:\n",
        "#     conda_dep.add_conda_package(conda_package)\n",
        "\n",
        "# for pip_package in pip_packages:\n",
        "#     conda_dep.add_pip_package(pip_package)\n",
        "\n",
        "# # Adds dependencies to PythonSection of myenv\n",
        "# rayEnv.python.conda_dependencies=conda_dep\n",
        "\n",
        "src = ScriptRunConfig(source_directory='job',\n",
        "                script='aml_job.py',\n",
        "                environment=rayEnv,\n",
        "                compute_target=ray_cluster,\n",
        "                distributed_job_config=PyTorchConfiguration(node_count=maxnode),\n",
        "                    # arguments = [\"--master_ip\",master_ip]\n",
        "                )\n",
        "run = Experiment(ws, exp).submit(src)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "cac4749ce6e64bfd07fafd5bf9c175e86cc05b1d81ce0d05824a22ecc489c963"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}